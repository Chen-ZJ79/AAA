{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM2H70fAXMQ8n+WHsRxB08j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"y4aSg0e1wvNb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761238675476,"user_tz":-480,"elapsed":28525,"user":{"displayName":"zj Chen","userId":"09020784127522418201"}},"outputId":"34f89a60-85db-4786-a78f-d9eedd101461"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# google drive mounted\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["# 解压\n","import zipfile, os\n","\n","zip_path = '/content/drive/MyDrive/Colab Notebooks/6204-2/Data/BraTS/MICCAI_BraTS2020.zip'\n","\n","assert os.path.exists(zip_path), 'Please update zip_path to your data location!'\n","with zipfile.ZipFile(zip_path, 'r') as zf:\n","    zf.extractall('/content/drive/MyDrive/Colab Notebooks/6204-2/Data/BraTS/')\n","print('✅ Data extracted to /6204-2/Data/BraTS/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o2dqyusiVXzt","executionInfo":{"status":"ok","timestamp":1760943035048,"user_tz":-480,"elapsed":584536,"user":{"displayName":"zj Chen","userId":"09020784127522418201"}},"outputId":"bef962b4-bf8f-4a52-c8ba-274dfaf58e46"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Data extracted to /6204-2/Data/BraTS/\n"]}]},{"cell_type":"code","source":["# 配环境\n","!cd \"/content/drive/MyDrive/Colab Notebooks/6204-3\"\n","!pip install -r \"/content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt\"\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"dQKlLFtsYxLq","executionInfo":{"status":"ok","timestamp":1761238704748,"user_tz":-480,"elapsed":22876,"user":{"displayName":"zj Chen","userId":"09020784127522418201"}},"outputId":"bf5ba364-e411-46b3-fd02-81e0b9cac048","collapsed":true},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (2.8.0+cu126)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 2)) (2.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 3)) (2.2.2)\n","Requirement already satisfied: blobfile in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 4)) (3.1.0)\n","Requirement already satisfied: nibabel in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 5)) (5.3.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 6)) (4.12.0.88)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 7)) (0.25.2)\n","Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 8)) (1.6.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 9)) (3.10.0)\n","Collecting batchgenerators (from -r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 10))\n","  Downloading batchgenerators-0.25.1.tar.gz (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting visdom (from -r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 11))\n","  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torchsummary in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 12)) (1.5.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (3.4.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 3)) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 3)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 3)) (2025.2)\n","Requirement already satisfied: pycryptodomex>=3.8 in /usr/local/lib/python3.12/dist-packages (from blobfile->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 4)) (3.23.0)\n","Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.12/dist-packages (from blobfile->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 4)) (2.5.0)\n","Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.12/dist-packages (from blobfile->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 4)) (5.4.0)\n","Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from nibabel->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 5)) (25.0)\n","Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 7)) (1.16.2)\n","Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 7)) (11.3.0)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 7)) (2.37.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 7)) (2025.10.16)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 7)) (0.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.24.0->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 8)) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.24.0->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 8)) (3.6.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 9)) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 9)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 9)) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 9)) (1.4.9)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 9)) (3.2.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from batchgenerators->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 10)) (1.0.0)\n","Collecting unittest2 (from batchgenerators->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 10))\n","  Downloading unittest2-1.1.0-py2.py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from visdom->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 11)) (2.32.4)\n","Requirement already satisfied: tornado in /usr/local/lib/python3.12/dist-packages (from visdom->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 11)) (6.5.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from visdom->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 11)) (1.17.0)\n","Requirement already satisfied: jsonpatch in /usr/local/lib/python3.12/dist-packages (from visdom->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 11)) (1.33)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.12/dist-packages (from visdom->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 11)) (1.9.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 1)) (3.0.3)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch->visdom->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 11)) (3.0.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->visdom->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 11)) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->visdom->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 11)) (3.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->visdom->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 11)) (2025.10.5)\n","Collecting argparse (from unittest2->batchgenerators->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 10))\n","  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n","Collecting traceback2 (from unittest2->batchgenerators->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 10))\n","  Downloading traceback2-1.4.0-py2.py3-none-any.whl.metadata (1.5 kB)\n","Collecting linecache2 (from traceback2->unittest2->batchgenerators->-r /content/drive/MyDrive/Colab Notebooks/6204-3/requirement.txt (line 10))\n","  Downloading linecache2-1.0.0-py2.py3-none-any.whl.metadata (1000 bytes)\n","Downloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n","Downloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n","Downloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n","Building wheels for collected packages: batchgenerators, visdom\n","  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for batchgenerators: filename=batchgenerators-0.25.1-py3-none-any.whl size=93088 sha256=dac257669f7312016b3b38019a0a6d4e46dbe068318dde43acabd93d2b4d7bc1\n","  Stored in directory: /root/.cache/pip/wheels/28/21/2b/7b25080f9f5847e6c3162b89d859d7cec9f3093158e56bd008\n","  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408195 sha256=6894a172c778a94cf59d375f3a0c35f553641903701b3cd79a72a64a103384f8\n","  Stored in directory: /root/.cache/pip/wheels/37/6c/38/64eeaa310e325aacda723e6df1f79ab5e9f31ba195264e04a8\n","Successfully built batchgenerators visdom\n","Installing collected packages: linecache2, argparse, traceback2, visdom, unittest2, batchgenerators\n","Successfully installed argparse-1.4.0 batchgenerators-0.25.1 linecache2-1.0.0 traceback2-1.4.0 unittest2-1.1.0 visdom-0.2.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse"]},"id":"4a669b09726748049d2f20a8ebb7833f"}},"metadata":{}}]},{"cell_type":"code","source":["# 检查数据路径和内容\n","import os\n","\n","data_dir = '/content/drive/MyDrive/Colab Notebooks/6204-3/Data/BraTS/MICCAI_BraTS2020_TrainingData'\n","csv_path = '/content/drive/MyDrive/Colab Notebooks/6204-3/Data/BraTS/MICCAI_BraTS2020_TrainingData/name_mapping.csv'\n","\n","print(f\"数据目录存在: {os.path.exists(data_dir)}\")\n","print(f\"CSV文件存在: {os.path.exists(csv_path)}\")\n","\n","if os.path.exists(data_dir):\n","    subdirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n","    print(f\"找到 {len(subdirs)} 个子目录\")\n","    if subdirs:\n","        print(f\"前3个子目录: {subdirs[:3]}\")\n","        first_dir = os.path.join(data_dir, subdirs[0])\n","        files = os.listdir(first_dir)\n","        print(f\"第一个子目录的文件: {files}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V0DNJ3WxkzjQ","executionInfo":{"status":"ok","timestamp":1761238730099,"user_tz":-480,"elapsed":3429,"user":{"displayName":"zj Chen","userId":"09020784127522418201"}},"outputId":"8192f7db-130b-46e9-9cb3-a524f12e1b72"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["数据目录存在: True\n","CSV文件存在: True\n","找到 369 个子目录\n","前3个子目录: ['BraTS20_Training_001', 'BraTS20_Training_002', 'BraTS20_Training_003']\n","第一个子目录的文件: ['BraTS20_Training_001_flair.nii', 'BraTS20_Training_001_seg.nii', 'BraTS20_Training_001_t1.nii', 'BraTS20_Training_001_t1ce.nii', 'BraTS20_Training_001_t2.nii']\n"]}]},{"cell_type":"code","source":["# stage 1 training\n","%cd \"/content/drive/MyDrive/Colab Notebooks/6204-3\"\n","! python scripts/segmentation_train.py \\\n","    --data_dir ./Data/BraTS/MICCAI_BraTS2020_TrainingData \\\n","    --csv_path ./Data/BraTS/MICCAI_BraTS2020_TrainingData/name_mapping.csv \\\n","    --out_dir ./results/stage1 \\\n","    --batch_size 2 \\\n","    --lr 1e-4 \\\n","    --lr_anneal_steps 500 \\\n","    --log_interval 50 \\\n","    --save_interval 100 \\\n","    --image_size 128 \\\n","    --num_channels 128 \\\n","    --diffusion_steps 100 \\\n","    --noise_schedule cosine \\\n","    --use_cls_head True \\\n","    --use_fp16 False\n","\n","# !python scripts/segmentation_train.py \\\n","#     --data_dir ./Data/BraTS/MICCAI_BraTS2020_TrainingData \\\n","#     --csv_path ./Data/BraTS/MICCAI_BraTS2020_TrainingData/name_mapping.csv \\\n","#     --out_dir ./results/demo_test \\\n","#     --batch_size 2 \\\n","#     --microbatch 1 \\\n","#     --lr 1e-4 \\\n","#     --weight_decay 0.0 \\\n","#     --lr_anneal_steps 5000 \\\n","#     --ema_rate 0.9999 \\\n","#     --log_interval 100 \\\n","#     --save_interval 1000 \\\n","#     --use_fp16 False \\\n","#     --gpu_dev 0 \\\n","#     --multi_gpu False \\\n","#     --image_size 128 \\\n","#     --num_channels 128 \\\n","#     --num_res_blocks 2 \\\n","#     --num_heads 4 \\\n","#     --num_head_channels 64 \\\n","#     --attention_resolutions \"32,16,8\" \\\n","#     --channel_mult \"1,2,2,2\" \\\n","#     --dropout 0.1 \\\n","#     --class_cond False \\\n","#     --use_checkpoint False \\\n","#     --use_scale_shift_norm True \\\n","#     --resblock_updown True \\\n","#     --use_new_attention_order False \\\n","#     --dpm_solver False \\\n","#     --version v2 \\\n","#     --use_cls_head True \\\n","#     --num_classes_cls 2 \\\n","#     --cls_pool \"adaptive\" \\\n","#     --learn_sigma False \\\n","#     --diffusion_steps 1000 \\\n","#     --noise_schedule \"cosine\" \\\n","#     --timestep_respacing \"\" \\\n","#     --use_kl False \\\n","#     --predict_xstart True \\\n","#     --rescale_timesteps False \\\n","#     --rescale_learned_sigmas False \\\n","#     --cls_focal_gamma 2.0 \\\n","#     --cls_alpha_pos 0.75 \\\n","#     --seg_loss_weight 1.0 \\\n","#     --cls_loss_weight 1.0 \\\n","#     --balanced_sampling False \\\n","#     --minority_ratio 0.3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hrblgoWXezqH","executionInfo":{"status":"ok","timestamp":1761242602788,"user_tz":-480,"elapsed":760229,"user":{"displayName":"zj Chen","userId":"09020784127522418201"}},"outputId":"38ab997e-d89a-46ed-f4e8-b23d1181c6c1"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/6204-3\n","Logging to ./results/stage1\n","creating data loader...\n","Loaded CSV with 369 entries\n","Grade mapping loaded: 369 subjects\n","Grade distribution: LGG=76, HGG=293\n","Class weights: LGG=2.428, HGG=0.630\n","Class weights calculated: tensor([2.4276, 0.6297])\n","Warning: Unexpected file format: W39_1998.09.19_Segm.nii\n","Warning: Skipping incomplete datapoint with missing sequences: ['seg']\n","Applied train split: 294 subjects selected from 368 total\n","============================================================\n","Dataset Statistics:\n","  Total samples: 369\n","  LGG samples: 76 (20.60%)\n","  HGG samples: 293 (79.40%)\n","  Alpha_LGG: 2.4276\n","  Alpha_HGG: 0.6297\n","============================================================\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","creating model and diffusion...\n","Classification head enabled in model\n","================================================================================\n","PARAMETER TRAINING STATUS\n","================================================================================\n","\n","📊 Summary:\n","   Trainable parameters: 491 (110,858,276 elements)\n","   Frozen parameters:    0 (0 elements)\n","   Total parameters:     491 (110,858,276 elements)\n","   Trainable percentage: 100.00%\n","\n","✅ Trainable parameters (491):\n","   - cls_head.2.weight\n","   - cls_head.2.bias\n","   - cls_head.5.weight\n","   - cls_head.5.bias\n","   - hwm.conv_blocks_context.* (48 parameters)\n","     ├─ hwm.conv_blocks_context.0.blocks.0.conv.weight\n","     ├─ ...\n","     └─ hwm.conv_blocks_context.5.1.blocks.0.instnorm.bias\n","   - hwm.conv_blocks_localization.* (40 parameters)\n","     ├─ hwm.conv_blocks_localization.0.0.blocks.0.conv.weight\n","     ├─ ...\n","     └─ hwm.conv_blocks_localization.4.1.blocks.0.instnorm.bias\n","   - hwm.seg_outputs.0.weight\n","   - input_blocks.0.0.weight\n","   - input_blocks.0.0.bias\n","   - input_blocks.1.* (10 parameters)\n","     ├─ input_blocks.1.0.in_layers.0.weight\n","     ├─ ...\n","     └─ input_blocks.1.0.out_layers.3.bias\n","   - input_blocks.10.* (18 parameters)\n","     ├─ input_blocks.10.0.in_layers.0.weight\n","     ├─ ...\n","     └─ input_blocks.10.1.proj_out.bias\n","   - input_blocks.11.* (16 parameters)\n","     ├─ input_blocks.11.0.in_layers.0.weight\n","     ├─ ...\n","     └─ input_blocks.11.1.proj_out.bias\n","   - input_blocks.12.0.op.weight\n","   - input_blocks.12.0.op.bias\n","   - input_blocks.13.* (18 parameters)\n","     ├─ input_blocks.13.0.in_layers.0.weight\n","     ├─ ...\n","     └─ input_blocks.13.1.proj_out.bias\n","   - input_blocks.14.* (16 parameters)\n","     ├─ input_blocks.14.0.in_layers.0.weight\n","     ├─ ...\n","     └─ input_blocks.14.1.proj_out.bias\n","   - input_blocks.2.* (10 parameters)\n","     ├─ input_blocks.2.0.in_layers.0.weight\n","     ├─ ...\n","     └─ input_blocks.2.0.out_layers.3.bias\n","   - input_blocks.3.0.op.weight\n","   - input_blocks.3.0.op.bias\n","   - input_blocks.4.* (10 parameters)\n","     ├─ input_blocks.4.0.in_layers.0.weight\n","     ├─ ...\n","     └─ input_blocks.4.0.out_layers.3.bias\n","   - input_blocks.5.* (10 parameters)\n","     ├─ input_blocks.5.0.in_layers.0.weight\n","     ├─ ...\n","     └─ input_blocks.5.0.out_layers.3.bias\n","   - input_blocks.6.0.op.weight\n","   - input_blocks.6.0.op.bias\n","   - input_blocks.7.* (12 parameters)\n","     ├─ input_blocks.7.0.in_layers.0.weight\n","     ├─ ...\n","     └─ input_blocks.7.0.skip_connection.bias\n","   - input_blocks.8.* (10 parameters)\n","     ├─ input_blocks.8.0.in_layers.0.weight\n","     ├─ ...\n","     └─ input_blocks.8.0.out_layers.3.bias\n","   - input_blocks.9.0.op.weight\n","   - input_blocks.9.0.op.bias\n","   - middle_block.0.* (10 parameters)\n","     ├─ middle_block.0.in_layers.0.weight\n","     ├─ ...\n","     └─ middle_block.0.out_layers.3.bias\n","   - middle_block.1.* (6 parameters)\n","     ├─ middle_block.1.norm.weight\n","     ├─ ...\n","     └─ middle_block.1.proj_out.bias\n","   - middle_block.2.* (10 parameters)\n","     ├─ middle_block.2.in_layers.0.weight\n","     ├─ ...\n","     └─ middle_block.2.out_layers.3.bias\n","   - out.0.weight\n","   - out.0.bias\n","   - out.2.weight\n","   - out.2.bias\n","   - output_blocks.0.* (18 parameters)\n","     ├─ output_blocks.0.0.in_layers.0.weight\n","     ├─ ...\n","     └─ output_blocks.0.1.proj_out.bias\n","   - output_blocks.1.* (18 parameters)\n","     ├─ output_blocks.1.0.in_layers.0.weight\n","     ├─ ...\n","     └─ output_blocks.1.1.proj_out.bias\n","   - output_blocks.10.* (12 parameters)\n","     ├─ output_blocks.10.0.in_layers.0.weight\n","     ├─ ...\n","     └─ output_blocks.10.0.skip_connection.bias\n","   - output_blocks.11.* (14 parameters)\n","     ├─ output_blocks.11.0.in_layers.0.weight\n","     ├─ ...\n","     └─ output_blocks.11.1.conv.bias\n","   - output_blocks.12.* (12 parameters)\n","     ├─ output_blocks.12.0.in_layers.0.weight\n","     ├─ ...\n","     └─ output_blocks.12.0.skip_connection.bias\n","   - output_blocks.13.* (12 parameters)\n","     ├─ output_blocks.13.0.in_layers.0.weight\n","     ├─ ...\n","     └─ output_blocks.13.0.skip_connection.bias\n","   - output_blocks.14.* (12 parameters)\n","     ├─ output_blocks.14.0.in_layers.0.weight\n","     ├─ ...\n","     └─ output_blocks.14.0.skip_connection.bias\n","   - output_blocks.2.* (20 parameters)\n","     ├─ output_blocks.2.0.in_layers.0.weight\n","     ├─ ...\n","     └─ output_blocks.2.2.conv.bias\n","   - output_blocks.3.* (18 parameters)\n","     ├─ output_blocks.3.0.in_layers.0.weight\n","     ├─ ...\n","     └─ output_blocks.3.1.proj_out.bias\n","   - output_blocks.4.* (18 parameters)\n","     ├─ output_blocks.4.0.in_layers.0.weight\n","     ├─ ...\n","     └─ output_blocks.4.1.proj_out.bias\n","   - output_blocks.5.* (20 parameters)\n","     ├─ output_blocks.5.0.in_layers.0.weight\n","     ├─ ...\n","     └─ output_blocks.5.2.conv.bias\n","   - output_blocks.6.* (12 parameters)\n","     ├─ output_blocks.6.0.in_layers.0.weight\n","     ├─ ...\n","     └─ output_blocks.6.0.skip_connection.bias\n","   - output_blocks.7.* (12 parameters)\n","     ├─ output_blocks.7.0.in_layers.0.weight\n","     ├─ ...\n","     └─ output_blocks.7.0.skip_connection.bias\n","   - output_blocks.8.* (14 parameters)\n","     ├─ output_blocks.8.0.in_layers.0.weight\n","     ├─ ...\n","     └─ output_blocks.8.1.conv.bias\n","   - output_blocks.9.* (12 parameters)\n","     ├─ output_blocks.9.0.in_layers.0.weight\n","     ├─ ...\n","     └─ output_blocks.9.0.skip_connection.bias\n","   - time_embed.0.weight\n","   - time_embed.0.bias\n","   - time_embed.2.weight\n","   - time_embed.2.bias\n","\n","🔍 Classification Head Status:\n","   ✅ Gradient detachment: ENABLED\n","      → Classification gradients will NOT affect segmentation network\n","      → Training mode: Stage 1 (Segmentation-focused)\n","================================================================================\n","\n","training...\n","---------------------------\n","| cls_acc      | 0        |\n","| cls_auc      | nan      |\n","| cls_f1       | 0        |\n","| grad_norm    | 1        |\n","| loss         | 0.997    |\n","| loss_cal     | 0.157    |\n","| loss_cal_q1  | 0.153    |\n","| loss_cal_q2  | 0.162    |\n","| loss_cls     | 0.271    |\n","| loss_diff    | 0.997    |\n","| loss_diff_q1 | 0.988    |\n","| loss_diff_q2 | 1        |\n","| loss_q1      | 0.988    |\n","| loss_q2      | 1        |\n","| loss_seg     | 2.57     |\n","| loss_total   | 1.42     |\n","| param_norm   | 233      |\n","| samples      | 2        |\n","| seg_dice     | 8.38e-09 |\n","| seg_iou      | 8.38e-09 |\n","| sigma_cls    | 1        |\n","| sigma_seg    | 1        |\n","| step         | 0        |\n","---------------------------\n","saving model 0...\n","saving model 0.9999...\n","/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n","  warnings.warn(  # warn only once\n","---------------------------\n","| cls_acc      | 1        |\n","| cls_auc      | 1        |\n","| cls_f1       | 1        |\n","| grad_norm    | 1        |\n","| loss         | 0.99     |\n","| loss_cal     | 0.121    |\n","| loss_cal_q0  | 0.128    |\n","| loss_cal_q1  | 0.122    |\n","| loss_cal_q2  | 0.124    |\n","| loss_cal_q3  | 0.108    |\n","| loss_cls     | 0.143    |\n","| loss_diff    | 0.99     |\n","| loss_diff_q0 | 0.993    |\n","| loss_diff_q1 | 0.993    |\n","| loss_diff_q2 | 0.99     |\n","| loss_diff_q3 | 0.983    |\n","| loss_q0      | 0.993    |\n","| loss_q1      | 0.993    |\n","| loss_q2      | 0.99     |\n","| loss_q3      | 0.983    |\n","| loss_seg     | 1.94     |\n","| loss_total   | 1.03     |\n","| param_norm   | 233      |\n","| samples      | 102      |\n","| seg_dice     | 0.0581   |\n","| seg_iou      | 0.0299   |\n","| sigma_cls    | 0.995    |\n","| sigma_seg    | 1.01     |\n","| step         | 50       |\n","---------------------------\n","---------------------------\n","| cls_acc      | 1        |\n","| cls_auc      | 1        |\n","| cls_f1       | 1        |\n","| grad_norm    | 1        |\n","| loss         | 0.919    |\n","| loss_cal     | 0.0788   |\n","| loss_cal_q0  | 0.0711   |\n","| loss_cal_q1  | 0.0844   |\n","| loss_cal_q2  | 0.0751   |\n","| loss_cal_q3  | 0.0817   |\n","| loss_cls     | 0.203    |\n","| loss_diff    | 0.919    |\n","| loss_diff_q0 | 0.943    |\n","| loss_diff_q1 | 0.896    |\n","| loss_diff_q2 | 0.887    |\n","| loss_diff_q3 | 0.945    |\n","| loss_q0      | 0.943    |\n","| loss_q1      | 0.896    |\n","| loss_q2      | 0.887    |\n","| loss_q3      | 0.945    |\n","| loss_seg     | 1.4      |\n","| loss_total   | 0.789    |\n","| param_norm   | 233      |\n","| samples      | 202      |\n","| seg_dice     | 0.0245   |\n","| seg_iou      | 0.0124   |\n","| sigma_cls    | 0.988    |\n","| sigma_seg    | 1.01     |\n","| step         | 100      |\n","---------------------------\n","saving model 0...\n","saving model 0.9999...\n","/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n","  warnings.warn(  # warn only once\n","---------------------------\n","| cls_acc      | 1        |\n","| cls_auc      | nan      |\n","| cls_f1       | 1        |\n","| grad_norm    | 0.995    |\n","| loss         | 0.815    |\n","| loss_cal     | 0.0529   |\n","| loss_cal_q0  | 0.0507   |\n","| loss_cal_q1  | 0.0567   |\n","| loss_cal_q2  | 0.0507   |\n","| loss_cal_q3  | 0.0529   |\n","| loss_cls     | 0.0349   |\n","| loss_diff    | 0.815    |\n","| loss_diff_q0 | 0.778    |\n","| loss_diff_q1 | 0.841    |\n","| loss_diff_q2 | 0.857    |\n","| loss_diff_q3 | 0.778    |\n","| loss_q0      | 0.778    |\n","| loss_q1      | 0.841    |\n","| loss_q2      | 0.857    |\n","| loss_q3      | 0.778    |\n","| loss_seg     | 1.18     |\n","| loss_total   | 0.586    |\n","| param_norm   | 233      |\n","| samples      | 302      |\n","| seg_dice     | 0.0385   |\n","| seg_iou      | 0.0196   |\n","| sigma_cls    | 0.982    |\n","| sigma_seg    | 1.02     |\n","| step         | 150      |\n","---------------------------\n","---------------------------\n","| cls_acc      | 0.5      |\n","| cls_auc      | nan      |\n","| cls_f1       | 0.667    |\n","| grad_norm    | 1        |\n","| loss         | 0.505    |\n","| loss_cal     | 0.043    |\n","| loss_cal_q0  | 0.043    |\n","| loss_cal_q1  | 0.0412   |\n","| loss_cal_q2  | 0.0428   |\n","| loss_cal_q3  | 0.0452   |\n","| loss_cls     | 0.143    |\n","| loss_diff    | 0.505    |\n","| loss_diff_q0 | 0.719    |\n","| loss_diff_q1 | 0.484    |\n","| loss_diff_q2 | 0.333    |\n","| loss_diff_q3 | 0.457    |\n","| loss_q0      | 0.719    |\n","| loss_q1      | 0.484    |\n","| loss_q2      | 0.333    |\n","| loss_q3      | 0.457    |\n","| loss_seg     | 1.06     |\n","| loss_total   | 0.58     |\n","| param_norm   | 233      |\n","| samples      | 402      |\n","| seg_dice     | 0.00242  |\n","| seg_iou      | 0.00121  |\n","| sigma_cls    | 0.977    |\n","| sigma_seg    | 1.02     |\n","| step         | 200      |\n","---------------------------\n","saving model 0...\n","saving model 0.9999...\n","/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n","  warnings.warn(  # warn only once\n","[rank0]: Traceback (most recent call last):\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-3/scripts/segmentation_train.py\", line 299, in <module>\n","[rank0]:     main()\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-3/scripts/segmentation_train.py\", line 262, in main\n","[rank0]:     ).run_loop()\n","[rank0]:       ^^^^^^^^^^\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-3/guided_diffusion/train_util.py\", line 223, in run_loop\n","[rank0]:     batch, cond, grade_label, name = next(data_iter)\n","[rank0]:                                      ^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 734, in __next__\n","[rank0]:     data = self._next_data()\n","[rank0]:            ^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1492, in _next_data\n","[rank0]:     idx, data = self._get_data()\n","[rank0]:                 ^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1444, in _get_data\n","[rank0]:     success, data = self._try_get_data()\n","[rank0]:                     ^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1285, in _try_get_data\n","[rank0]:     data = self._data_queue.get(timeout=timeout)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/lib/python3.12/queue.py\", line 180, in get\n","[rank0]:     self.not_empty.wait(remaining)\n","[rank0]:   File \"/usr/lib/python3.12/threading.py\", line 359, in wait\n","[rank0]:     gotit = waiter.acquire(True, timeout)\n","[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]: KeyboardInterrupt\n","[rank0]:[W1023 18:03:17.530055796 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"]}]},{"cell_type":"markdown","source":["\n","### `--image_size 128`\n","**含义**: 输入图像尺寸  \n","**单位**: 像素  \n","**作用**:\n","- 将所有图像resize到`128×128`\n","- UNet的输入必须是正方形\n","\n","### `--batch_size 2`\n","**含义**: 每次训练的样本数  \n","**作用**:\n","- 控制每次梯度更新使用多少样本\n","- 影响显存占用和训练稳定性\n","\n","\n","**batch_size对训练的影响**:\n","```\n","更大的batch_size:\n","✅ 梯度更稳定\n","✅ 可以用更大的学习率\n","❌ 显存需求高\n","❌ 可能陷入尖锐最小值\n","\n","更小的batch_size:\n","✅ 显存需求低\n","✅ 正则化效果（噪声帮助泛化）\n","❌ 梯度不稳定\n","❌ 需要更小的学习率\n","```\n","\n","### `--num_channels 128`\n","**含义**: UNet的基础通道数  \n","**作用**:\n","- 控制模型的\"宽度\"\n","- 所有层的通道数都基于这个值\n","\n","**实际通道数**:\n","```python\n","# 如果num_channels=128, channel_mult=(1,2,4)\n","Encoder:\n","  Block 0: 128 channels   (128 * 1)\n","  Block 1: 256 channels   (128 * 2)\n","  Block 2: 512 channels   (128 * 4)\n","\n","Bottleneck: 512 channels\n","\n","Decoder:\n","  Block 0: 512 channels\n","  Block 1: 256 channels\n","  Block 2: 128 channels\n","```\n","\n","### `--num_res_blocks 2`\n","**含义**: 每个分辨率层级的ResNet块数量  \n","**作用**:\n","- 控制模型的\"深度\"\n","- 更多块 = 更强表达能力\n","\n","### `--num_heads 1`\n","**含义**: 多头注意力的头数  \n","**作用**:\n","- Transformer注意力机制的并行头数\n","- 用于捕捉不同类型的特征\n","\n","### `--attention_resolutions 16`\n","**含义**: 在哪些分辨率使用注意力机制  \n","**作用**:\n","- 控制注意力的应用位置\n","- 逗号分隔多个值，如16,8\n","```\n","--attention_resolutions 16\n","→ 只在16×16分辨率使用注意力\n","\n","--attention_resolutions 16,8\n","→ 在16×16和8×8都使用注意力\n","```\n","\n","**为什么选16**:\n","- 底层（高分辨率）不需要全局注意力\n","- 中间层（16×16）正好适合\n","- 平衡性能和速度\n","\n","\n","### `--diffusion_steps 100`\n","**含义**: 扩散过程的时间步数  \n","\n","```python\n","# 前向过程 (加噪)\n","for t in range(diffusion_steps):\n","    x_t = sqrt(alpha_t) * x_0 + sqrt(1-alpha_t) * noise\n","\n","# 反向过程 (去噪)\n","for t in range(diffusion_steps, 0, -1):\n","    x_t-1 = model_predict(x_t, t)\n","```\n","\n","### `--noise_schedule linear`\n","**含义**: 噪声添加的时间表  \n","**可选值**: `linear`, `cosine`\n","\n","**数学定义**:\n","```python\n","# linear (传统DDPM)\n","beta_t = beta_start + (beta_end - beta_start) * t / T\n","# 特点: 线性增加噪声\n","\n","# cosine (改进版)\n","beta_t = 根据余弦函数设计\n","# 特点: 早期加噪慢，后期加噪快\n","```\n","**linear**:\n","- 标准DDPM配置\n","- 简单稳定\n","- 医学图像效果好\n","\n","### `--lr 1e-4` (或`1e-3`, `1e-5`)\n","**含义**: 学习率 (Learning Rate)  \n","``\n","\n","**三个阶段的学习率**:\n","```\n","Stage 1: lr=1e-4 (0.0001)\n","原因: 标准UNet学习率\n","目标: 稳定训练分割网络\n","\n","Stage 2: lr=1e-3 (0.001) ↑10倍\n","原因: 分类头新初始化，可以快\n","目标: 快速收敛分类任务\n","\n","Stage 3: lr=1e-5 (0.00001) ↓100倍\n","原因: 微调，避免破坏已有权重\n","目标: 联合优化两个任务\n","```\n","### `--lr_anneal_steps 5000` (或`2000`, `1000`)\n","**含义**: 学习率退火的总步数  \n","**作用**:\n","- 训练终止条件\n","- 学习率逐渐衰减到0\n","\n","### `--weight_decay 0.0`\n","**含义**: 权重衰减（L2正则化）  \n","**作用**:\n","- 防止过拟合\n","- 让权重保持较小值\n","- 医学图像数据集较小，不易过拟合\n","- 扩散模型本身有正则化效果\n","- 可以设为`1e-4`如果过拟合\n","\n","### `--microbatch -1`\n","**含义**: 梯度累积的微批次大小  \n","**作用**:\n","- 在显存不足时模拟大batch_size\n","- `-1`表示不使用，等于`batch_size`\n","\n","**示例**:\n","```python\n","# 正常训练\n","batch_size = 8  # 需要24GB显存\n","\n","# 梯度累积\n","batch_size = 8\n","microbatch = 2  # 只需要6GB显存\n","# 内部: 分4次前向，累积梯度，1次更新\n","```\n","\n","**为什么设为-1**:\n","- batch_size=2已经很小了\n","- 不需要梯度累积\n","\n","\n","### `--save_interval 1000` (或`500`, `200`)\n","**含义**: 每隔多少步保存一次模型  \n","\n","```\n","Stage 1: 1000步/次\n","原因: 训练时间长，不需要太频繁\n","\n","Stage 2: 500步/次\n","原因: 收敛快，需要更密集的checkpoint\n","\n","Stage 3: 200步/次\n","原因: 微调，需要随时停止\n","```\n","\n","### `--log_interval 100` (或`50`, `10`)\n","**含义**: 每隔多少步记录一次日志  \n","\n","### `--resume_checkpoint ./results_stage1/savedmodel005000.pt`\n","**含义**: 从哪个checkpoint恢复训练  \n","- 加载预训练模型\n","- 继续训练或微调\n","```\n","Stage 1 → Stage 2:\n","--resume_checkpoint ./results_stage1/savedmodel005000.pt\n","\n","Stage 2 → Stage 3:\n","--resume_checkpoint ./results_stage2/savedmodel002000.pt\n","\n","训练中断恢复:\n","--resume_checkpoint ./results_stage1/savedmodel003000.pt\n","```\n","\n","### `--use_cls_head True`\n","**含义**: 是否启用分类头  \n","**作用**:\n","- 开启多任务学习（分割+分类）\n","- 如果为`False`，只做分割\n","\n","### `--focal_gamma 2.0`\n","**含义**: 分类Focal Loss的gamma参数  \n","**作用**:\n","- 控制对难分样本的关注度\n","- 处理类别不平衡\n","\n","**数学**:\n","```python\n","# 标准交叉熵\n","CE = -log(p_t)\n","\n","# Focal Loss\n","FL = -(1 - p_t)^gamma * log(p_t)\n","     ↑\n","     难度权重\n","```\n","**为什么选2.0**:\n","- 原始Focal Loss论文的推荐值\n","\n","### `--seg_focal_gamma 1.5`\n","**含义**: 分割Focal Loss的gamma参数  \n","\n","**为什么选1.5**:\n","- 比分类稍温和（分割已经够难了）\n","- 避免过度关注困难像素\n","- 实验效果好\n","\n","### `--seg_focal_lambda 0.5`\n","**含义**: 分割Focal Loss的权重  \n","**作用**:\n","- 控制Focal Loss在分割总损失中的比例\n","\n","**分割总损失**:\n","```python\n","loss_seg = (1 - lambda) * Dice_Loss + lambda * Focal_Loss\n","loss_seg = 0.5 * Dice + 0.5 * Focal  # lambda=0.5\n","```\n","\n","**为什么选0.5**:\n","- Dice和Focal各占一半\n","- 平衡两种损失的优点\n","- Dice: 全局优化\n","- Focal: 困难像素\n","\n","### `--use_fp16 False`\n","**含义**: 是否使用混合精度训练  \n","**作用**:\n","- FP16（半精度）可以加速训练\n","- 减少显存占用\n","\n","**为什么设为False**:\n","- 混合精度在医学图像上不稳定\n","\n","### `--schedule_sampler uniform`\n","**含义**: 时间步采样策略  \n","**可选值**: `uniform`, `loss-second-moment`\n","\n","**uniform (均匀采样)**:\n","```python\n","t = random.randint(0, diffusion_steps)\n","# 每个时间步等概率\n","```\n","\n","### **EMA (指数移动平均)**\n","```bash\n","--ema_rate 0.9999\n","```\n","**含义**: EMA动量系数  \n","**作用**: 维护参数的移动平均版本\n","```python\n","ema_params = ema_rate * ema_params + (1 - ema_rate) * current_params\n","```\n","**`--channel_mult \"1,2,2,2\"`**:\n","- **含义**: 每层的通道倍数\n","- **作用**: 控制网络容量\n","- **你的设置**: [1,2,2,2] ✅\n","- **建议**:\n","  - 快速实验: `[1,2,2,2]` ✅\n","  - 完整训练: `[1,2,4,8]`\n","\n","**bottleneck_channels计算**:\n","```python\n","bottleneck_channels = channel_mult[-1] * num_channels\n","                    = 2 * 128\n","                    = 256\n","```\n","这决定了分类头的输入维度！\n","\n","**`--resblock_updown True`**:\n","- **含义**: 上下采样是否使用残差块\n","- **你的设置**: True ✅ (更稳定)\n","\n","**`--use_scale_shift_norm True`**:\n","- **含义**: 使用条件归一化 (FiLM)\n","- **作用**: 允许时间步嵌入影响归一化\n","- **你的设置**: True ✅\n","\n","**`--dropout 0.1`**:\n","- **含义**: Dropout比例\n","- **作用**: 防止过拟合\n","- **你的设置**: 0.1 = 10% ✅\n","\n","### **`--predict_xstart True`**\n","**含义**: 模型预测什么  \n","**选项**:\n","- `True`: 预测原始图像 x₀\n","- `False`: 预测噪声 ε\n","\n","**你的设置**: True ✅  \n","**建议**: True (对分割任务更直接)\n","\n","### **`--learn_sigma False`**\n","**含义**: 是否学习方差  \n","**作用**:\n","- `False`: 使用固定方差\n","- `True`: 模型预测均值和方差\n","\n","**你的设置**: False ✅  \n","**建议**: False (减少不稳定性)\n","\n","\n","\n"],"metadata":{"id":"-0w0qRfHBw0B"}},{"cell_type":"markdown","source":["```\n","| loss          | 0.864 | 总损失 (不确定性加权后)\n","| loss_seg      | 2.14  | 分割损失 (扩散+校准)\n","| loss_cls      | 0.00775 | 分类损失 (Focal Loss)\n","| loss_total    | 1.07  | 总损失 (分割+分类)\n","| loss_diff     | 0.76  | 扩散损失 (MSE)\n","| loss_cal      | 0.0837 | 校准损失\n","| loss_cal_q0   | 0.0794 | 校准损失25%分位数\n","| loss_cal_q1   | 0.0778 | 校准损失50%分位数\n","| loss_cal_q3   | 0.0882 | 校准损失75%分位数\n","```\n","\n","#### **Segmentation**:\n","```\n","| seg_dice      | 0.141 | Dice\n","| seg_iou       | 0.0759 | IoU\n","```\n","\n","#### **Classification**:\n","```\n","| cls_acc       | 1     | Classification Accuracy\n","| cls_f1        | 1     | F1\n","| cls_auc       | nan   | AUC (0-1, 越高越好, nan表示只有一类)\n","```\n","\n","#### **不确定性参数**:\n","```\n","(***这个是cursor给我加的什么七七八八的权重，暂时没明白有没有用，不然删掉也可以）\n","| sigma_seg     | 1.03  | 分割任务的不确定性权重\n","| sigma_cls     | 1.03  | 分类任务的不确定性权重\n","```\n","\n","#### **Training**:\n","```\n","| step          | 200   | 当前训练步数\n","| samples       | 201   | 已处理的样本数\n","| grad_norm     | 44.7  | 梯度范数 (应该<10, 过高表示梯度爆炸)\n","| param_norm    | 187   | 参数范数\n","```\n","#### **Warning**:\n","- **loss**: 突然跳跃或NaN\n","- **grad_norm**: >50 梯度爆炸\n","- **cls_auc**: nan 表示只有一类样本\n","- **seg_dice**: <0.1 分割效果很差\n","\n","```bash\n","--lr 1e-4              # 学习率\n","--batch_size 4         # 批次大小\n","--diffusion_steps 1000 # 扩散步数\n","--focal_gamma 2.0      # Focal Loss的γ\n","--seg_focal_gamma 1.5  # 分割Focal Loss的γ\n","--seg_focal_lambda 0.5 # 分割Focal Loss的权重\n","```"],"metadata":{"id":"ZT0kaiiS5a8C"}},{"cell_type":"code","source":["# validation/sample, only target on valuable mask\n","%cd \"/content/drive/MyDrive/Colab Notebooks/6204-2\"\n","\n","! python scripts/segmentation_sample.py \\\n","  --data_name BRATS \\\n","  --data_dir Data/BraTS/MICCAI_BraTS2020_TrainingData \\\n","  --out_dir ./results_r \\\n","  --image_size 128 \\\n","  --num_channels 128 \\\n","  --num_res_blocks 1 \\\n","  --num_heads 1 \\\n","  --learn_sigma True \\\n","  --use_scale_shift_norm False \\\n","  --attention_resolutions 32 \\\n","  --diffusion_steps 100 \\\n","  --noise_schedule linear \\\n","  --rescale_learned_sigmas False \\\n","  --rescale_timesteps False \\\n","  --batch_size 1 \\\n","  --use_ddim False \\\n","  --model_path ./results_demo/savedmodel000300.pt \\\n","  --num_ensemble 2 \\\n","  --debug True \\\n","  --use_cls_head True \\\n","  --csv_path Data/BraTS/MICCAI_BraTS2020_TrainingData/name_mapping.csv \\\n","  --num_eval_cases 1"],"metadata":{"id":"WFWw7dbxd5RC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761119065960,"user_tz":-480,"elapsed":40963,"user":{"displayName":"zj Chen","userId":"09020784127522418201"}},"outputId":"5204b9f9-c9c5-4978-c3a8-d8694ac5a290","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/6204-2\n","Logging to ./results_r\n","Loaded CSV with 369 entries\n","Grade mapping loaded: 369 subjects\n","Grade distribution: LGG=76, HGG=293\n","Class weights: LGG=2.428, HGG=0.630\n","Class weights calculated: tensor([2.4276, 0.6297])\n","Warning: Unexpected file format: W39_1998.09.19_Segm.nii\n","Warning: Skipping incomplete datapoint with missing sequences: ['seg']\n","Applied validation split: 19 subjects selected from 368 total\n","creating model and diffusion...\n","Loading model from ./results_demo/savedmodel000300.pt\n","Starting evaluation on validation set (case-wise analysis)...\n","Processing case 1/1: BraTS20_Training_013\n","Processing slice 55 of case 013: BraTS20_Training_013_55\n","no dpm-solver\n","Time for sample 1: 3706.09ms\n","no dpm-solver\n","[rank0]: Traceback (most recent call last):\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-2/scripts/segmentation_sample.py\", line 405, in <module>\n","[rank0]:     main()\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-2/scripts/segmentation_sample.py\", line 235, in main\n","[rank0]:     sample, x_noisy, org, cal, cal_out = sample_fn(\n","[rank0]:                                          ^^^^^^^^^^\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-2/guided_diffusion/gaussian_diffusion.py\", line 566, in p_sample_loop_known\n","[rank0]:     for sample in self.p_sample_loop_progressive(\n","[rank0]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-2/guided_diffusion/gaussian_diffusion.py\", line 651, in p_sample_loop_progressive\n","[rank0]:     out = self.p_sample(\n","[rank0]:           ^^^^^^^^^^^^^^\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-2/guided_diffusion/gaussian_diffusion.py\", line 445, in p_sample\n","[rank0]:     out = self.p_mean_variance(\n","[rank0]:           ^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-2/guided_diffusion/respace.py\", line 90, in p_mean_variance\n","[rank0]:     return super().p_mean_variance(self._wrap_model(model), *args, **kwargs)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-2/guided_diffusion/gaussian_diffusion.py\", line 272, in p_mean_variance\n","[rank0]:     model_output = model(x, self._scale_timesteps(t), **model_kwargs)\n","[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-2/guided_diffusion/respace.py\", line 135, in __call__\n","[rank0]:     return self.model(x, new_ts, **kwargs)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","[rank0]:     return self._call_impl(*args, **kwargs)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","[rank0]:     return forward_call(*args, **kwargs)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-2/guided_diffusion/unet.py\", line 1127, in forward\n","[rank0]:     h = module(h, emb)\n","[rank0]:         ^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","[rank0]:     return self._call_impl(*args, **kwargs)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","[rank0]:     return forward_call(*args, **kwargs)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-2/guided_diffusion/unet.py\", line 84, in forward\n","[rank0]:     x = layer(x, emb)\n","[rank0]:         ^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","[rank0]:     return self._call_impl(*args, **kwargs)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","[rank0]:     return forward_call(*args, **kwargs)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-2/guided_diffusion/unet.py\", line 297, in forward\n","[rank0]:     return checkpoint(\n","[rank0]:            ^^^^^^^^^^^\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-2/guided_diffusion/nn.py\", line 142, in checkpoint\n","[rank0]:     return func(*inputs)\n","[rank0]:            ^^^^^^^^^^^^^\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-2/guided_diffusion/unet.py\", line 310, in _forward\n","[rank0]:     emb_out = self.emb_layers(emb).type(h.dtype)\n","[rank0]:               ^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","[rank0]:     return self._call_impl(*args, **kwargs)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","[rank0]:     return forward_call(*args, **kwargs)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 244, in forward\n","[rank0]:     input = module(input)\n","[rank0]:             ^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","[rank0]:     return self._call_impl(*args, **kwargs)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","[rank0]:     return forward_call(*args, **kwargs)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n","[rank0]:     return F.linear(input, self.weight, self.bias)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]: KeyboardInterrupt\n","[rank0]:[W1022 07:44:24.334386563 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"]}]},{"cell_type":"markdown","source":["sample没解决的问题：dice计算检查一下有没有错，可视化最后的图片有点杂。log的日志比较乱。"],"metadata":{"id":"E2vZbvPU4LXQ"}},{"cell_type":"code","source":["%cd \"/content/drive/MyDrive/Colab Notebooks/6204-2\"\n","\n","! python scripts/segmentation_train3stages.py \\\n","  --stage 1 \\\n","  --data_name BRATS \\\n","  --data_dir Data/BraTS/MICCAI_BraTS2020_TrainingData \\\n","  --out_dir ./results_light \\\n","  --image_size 128 \\\n","  --num_channels 128 \\\n","  --num_res_blocks 1 \\\n","  --channel_mult \"1,2,3,4\" \\\n","  --attention_resolutions \"16\" \\\n","  --diffusion_steps 1000 \\\n","  --lr 1e-4 \\\n","  --batch_size 8 \\\n","  --save_interval 2000 \\\n","  --log_interval 50"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7wd6Zy1GJDW2","executionInfo":{"status":"ok","timestamp":1761143111169,"user_tz":-480,"elapsed":541514,"user":{"displayName":"zj Chen","userId":"09020784127522418201"}},"outputId":"f3b0d8d2-b302-460c-8e8a-278588a32c25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/6204-2\n","Logging to ./results_light_stage1\n","================================================================================\n","MedSegDiff-V2: Staged Training - STAGE 1\n","================================================================================\n","阶段1: 只训练分割 (扩散模型)\n","  - 专注于学习肿瘤的pixel-level细节\n","  - 训练到Dice/校准稳定\n","================================================================================\n","creating data loader...\n","use_cls_head = False (Stage 1)\n","Warning: Unexpected file format: W39_1998.09.19_Segm.nii\n","Warning: Skipping incomplete datapoint with missing sequences: ['seg']\n","Applied train split: 294 subjects selected from 368 total\n","creating model and diffusion...\n","model.use_cls_head = False\n","\n","============================================================\n","Parameter Freezing Strategy:\n","============================================================\n","Stage 1: 冻结分类头 (4 参数)\n","可训练: Encoder + Decoder + Diffusion\n","  [TRAINABLE] time_embed.0.weight: 65536\n","  [TRAINABLE] time_embed.0.bias: 512\n","  [TRAINABLE] time_embed.2.weight: 262144\n","  [TRAINABLE] time_embed.2.bias: 512\n","  [TRAINABLE] input_blocks.0.0.weight: 5760\n","  [TRAINABLE] input_blocks.0.0.bias: 128\n","  [TRAINABLE] input_blocks.1.0.in_layers.0.weight: 128\n","  [TRAINABLE] input_blocks.1.0.in_layers.0.bias: 128\n","  [TRAINABLE] input_blocks.1.0.in_layers.2.weight: 147456\n","  [TRAINABLE] input_blocks.1.0.in_layers.2.bias: 128\n","  [TRAINABLE] input_blocks.1.0.emb_layers.1.weight: 131072\n","  [TRAINABLE] input_blocks.1.0.emb_layers.1.bias: 256\n","  [TRAINABLE] input_blocks.1.0.out_layers.0.weight: 128\n","  [TRAINABLE] input_blocks.1.0.out_layers.0.bias: 128\n","  [TRAINABLE] input_blocks.1.0.out_layers.3.weight: 147456\n","  [TRAINABLE] input_blocks.1.0.out_layers.3.bias: 128\n","  [TRAINABLE] input_blocks.2.0.op.weight: 147456\n","  [TRAINABLE] input_blocks.2.0.op.bias: 128\n","  [TRAINABLE] input_blocks.3.0.in_layers.0.weight: 128\n","  [TRAINABLE] input_blocks.3.0.in_layers.0.bias: 128\n","  [TRAINABLE] input_blocks.3.0.in_layers.2.weight: 294912\n","  [TRAINABLE] input_blocks.3.0.in_layers.2.bias: 256\n","  [TRAINABLE] input_blocks.3.0.emb_layers.1.weight: 262144\n","  [TRAINABLE] input_blocks.3.0.emb_layers.1.bias: 512\n","  [TRAINABLE] input_blocks.3.0.out_layers.0.weight: 256\n","  [TRAINABLE] input_blocks.3.0.out_layers.0.bias: 256\n","  [TRAINABLE] input_blocks.3.0.out_layers.3.weight: 589824\n","  [TRAINABLE] input_blocks.3.0.out_layers.3.bias: 256\n","  [TRAINABLE] input_blocks.3.0.skip_connection.weight: 32768\n","  [TRAINABLE] input_blocks.3.0.skip_connection.bias: 256\n","  [TRAINABLE] input_blocks.4.0.op.weight: 589824\n","  [TRAINABLE] input_blocks.4.0.op.bias: 256\n","  [TRAINABLE] input_blocks.5.0.in_layers.0.weight: 256\n","  [TRAINABLE] input_blocks.5.0.in_layers.0.bias: 256\n","  [TRAINABLE] input_blocks.5.0.in_layers.2.weight: 884736\n","  [TRAINABLE] input_blocks.5.0.in_layers.2.bias: 384\n","  [TRAINABLE] input_blocks.5.0.emb_layers.1.weight: 393216\n","  [TRAINABLE] input_blocks.5.0.emb_layers.1.bias: 768\n","  [TRAINABLE] input_blocks.5.0.out_layers.0.weight: 384\n","  [TRAINABLE] input_blocks.5.0.out_layers.0.bias: 384\n","  [TRAINABLE] input_blocks.5.0.out_layers.3.weight: 1327104\n","  [TRAINABLE] input_blocks.5.0.out_layers.3.bias: 384\n","  [TRAINABLE] input_blocks.5.0.skip_connection.weight: 98304\n","  [TRAINABLE] input_blocks.5.0.skip_connection.bias: 384\n","  [TRAINABLE] input_blocks.6.0.op.weight: 1327104\n","  [TRAINABLE] input_blocks.6.0.op.bias: 384\n","  [TRAINABLE] input_blocks.7.0.in_layers.0.weight: 384\n","  [TRAINABLE] input_blocks.7.0.in_layers.0.bias: 384\n","  [TRAINABLE] input_blocks.7.0.in_layers.2.weight: 1769472\n","  [TRAINABLE] input_blocks.7.0.in_layers.2.bias: 512\n","  [TRAINABLE] input_blocks.7.0.emb_layers.1.weight: 524288\n","  [TRAINABLE] input_blocks.7.0.emb_layers.1.bias: 1024\n","  [TRAINABLE] input_blocks.7.0.out_layers.0.weight: 512\n","  [TRAINABLE] input_blocks.7.0.out_layers.0.bias: 512\n","  [TRAINABLE] input_blocks.7.0.out_layers.3.weight: 2359296\n","  [TRAINABLE] input_blocks.7.0.out_layers.3.bias: 512\n","  [TRAINABLE] input_blocks.7.0.skip_connection.weight: 196608\n","  [TRAINABLE] input_blocks.7.0.skip_connection.bias: 512\n","  [TRAINABLE] input_blocks.7.1.norm.weight: 512\n","  [TRAINABLE] input_blocks.7.1.norm.bias: 512\n","  [TRAINABLE] input_blocks.7.1.qkv.weight: 786432\n","  [TRAINABLE] input_blocks.7.1.qkv.bias: 1536\n","  [TRAINABLE] input_blocks.7.1.proj_out.weight: 262144\n","  [TRAINABLE] input_blocks.7.1.proj_out.bias: 512\n","  [TRAINABLE] middle_block.0.in_layers.0.weight: 512\n","  [TRAINABLE] middle_block.0.in_layers.0.bias: 512\n","  [TRAINABLE] middle_block.0.in_layers.2.weight: 2359296\n","  [TRAINABLE] middle_block.0.in_layers.2.bias: 512\n","  [TRAINABLE] middle_block.0.emb_layers.1.weight: 524288\n","  [TRAINABLE] middle_block.0.emb_layers.1.bias: 1024\n","  [TRAINABLE] middle_block.0.out_layers.0.weight: 512\n","  [TRAINABLE] middle_block.0.out_layers.0.bias: 512\n","  [TRAINABLE] middle_block.0.out_layers.3.weight: 2359296\n","  [TRAINABLE] middle_block.0.out_layers.3.bias: 512\n","  [TRAINABLE] middle_block.1.norm.weight: 512\n","  [TRAINABLE] middle_block.1.norm.bias: 512\n","  [TRAINABLE] middle_block.1.qkv.weight: 786432\n","  [TRAINABLE] middle_block.1.qkv.bias: 1536\n","  [TRAINABLE] middle_block.1.proj_out.weight: 262144\n","  [TRAINABLE] middle_block.1.proj_out.bias: 512\n","  [TRAINABLE] middle_block.2.in_layers.0.weight: 512\n","  [TRAINABLE] middle_block.2.in_layers.0.bias: 512\n","  [TRAINABLE] middle_block.2.in_layers.2.weight: 2359296\n","  [TRAINABLE] middle_block.2.in_layers.2.bias: 512\n","  [TRAINABLE] middle_block.2.emb_layers.1.weight: 524288\n","  [TRAINABLE] middle_block.2.emb_layers.1.bias: 1024\n","  [TRAINABLE] middle_block.2.out_layers.0.weight: 512\n","  [TRAINABLE] middle_block.2.out_layers.0.bias: 512\n","  [TRAINABLE] middle_block.2.out_layers.3.weight: 2359296\n","  [TRAINABLE] middle_block.2.out_layers.3.bias: 512\n","  [TRAINABLE] output_blocks.0.0.in_layers.0.weight: 1024\n","  [TRAINABLE] output_blocks.0.0.in_layers.0.bias: 1024\n","  [TRAINABLE] output_blocks.0.0.in_layers.2.weight: 4718592\n","  [TRAINABLE] output_blocks.0.0.in_layers.2.bias: 512\n","  [TRAINABLE] output_blocks.0.0.emb_layers.1.weight: 524288\n","  [TRAINABLE] output_blocks.0.0.emb_layers.1.bias: 1024\n","  [TRAINABLE] output_blocks.0.0.out_layers.0.weight: 512\n","  [TRAINABLE] output_blocks.0.0.out_layers.0.bias: 512\n","  [TRAINABLE] output_blocks.0.0.out_layers.3.weight: 2359296\n","  [TRAINABLE] output_blocks.0.0.out_layers.3.bias: 512\n","  [TRAINABLE] output_blocks.0.0.skip_connection.weight: 524288\n","  [TRAINABLE] output_blocks.0.0.skip_connection.bias: 512\n","  [TRAINABLE] output_blocks.0.1.norm.weight: 512\n","  [TRAINABLE] output_blocks.0.1.norm.bias: 512\n","  [TRAINABLE] output_blocks.0.1.qkv.weight: 786432\n","  [TRAINABLE] output_blocks.0.1.qkv.bias: 1536\n","  [TRAINABLE] output_blocks.0.1.proj_out.weight: 262144\n","  [TRAINABLE] output_blocks.0.1.proj_out.bias: 512\n","  [TRAINABLE] output_blocks.1.0.in_layers.0.weight: 896\n","  [TRAINABLE] output_blocks.1.0.in_layers.0.bias: 896\n","  [TRAINABLE] output_blocks.1.0.in_layers.2.weight: 4128768\n","  [TRAINABLE] output_blocks.1.0.in_layers.2.bias: 512\n","  [TRAINABLE] output_blocks.1.0.emb_layers.1.weight: 524288\n","  [TRAINABLE] output_blocks.1.0.emb_layers.1.bias: 1024\n","  [TRAINABLE] output_blocks.1.0.out_layers.0.weight: 512\n","  [TRAINABLE] output_blocks.1.0.out_layers.0.bias: 512\n","  [TRAINABLE] output_blocks.1.0.out_layers.3.weight: 2359296\n","  [TRAINABLE] output_blocks.1.0.out_layers.3.bias: 512\n","  [TRAINABLE] output_blocks.1.0.skip_connection.weight: 458752\n","  [TRAINABLE] output_blocks.1.0.skip_connection.bias: 512\n","  [TRAINABLE] output_blocks.1.1.norm.weight: 512\n","  [TRAINABLE] output_blocks.1.1.norm.bias: 512\n","  [TRAINABLE] output_blocks.1.1.qkv.weight: 786432\n","  [TRAINABLE] output_blocks.1.1.qkv.bias: 1536\n","  [TRAINABLE] output_blocks.1.1.proj_out.weight: 262144\n","  [TRAINABLE] output_blocks.1.1.proj_out.bias: 512\n","  [TRAINABLE] output_blocks.1.2.conv.weight: 2359296\n","  [TRAINABLE] output_blocks.1.2.conv.bias: 512\n","  [TRAINABLE] output_blocks.2.0.in_layers.0.weight: 896\n","  [TRAINABLE] output_blocks.2.0.in_layers.0.bias: 896\n","  [TRAINABLE] output_blocks.2.0.in_layers.2.weight: 3096576\n","  [TRAINABLE] output_blocks.2.0.in_layers.2.bias: 384\n","  [TRAINABLE] output_blocks.2.0.emb_layers.1.weight: 393216\n","  [TRAINABLE] output_blocks.2.0.emb_layers.1.bias: 768\n","  [TRAINABLE] output_blocks.2.0.out_layers.0.weight: 384\n","  [TRAINABLE] output_blocks.2.0.out_layers.0.bias: 384\n","  [TRAINABLE] output_blocks.2.0.out_layers.3.weight: 1327104\n","  [TRAINABLE] output_blocks.2.0.out_layers.3.bias: 384\n","  [TRAINABLE] output_blocks.2.0.skip_connection.weight: 344064\n","  [TRAINABLE] output_blocks.2.0.skip_connection.bias: 384\n","  [TRAINABLE] output_blocks.3.0.in_layers.0.weight: 640\n","  [TRAINABLE] output_blocks.3.0.in_layers.0.bias: 640\n","  [TRAINABLE] output_blocks.3.0.in_layers.2.weight: 2211840\n","  [TRAINABLE] output_blocks.3.0.in_layers.2.bias: 384\n","  [TRAINABLE] output_blocks.3.0.emb_layers.1.weight: 393216\n","  [TRAINABLE] output_blocks.3.0.emb_layers.1.bias: 768\n","  [TRAINABLE] output_blocks.3.0.out_layers.0.weight: 384\n","  [TRAINABLE] output_blocks.3.0.out_layers.0.bias: 384\n","  [TRAINABLE] output_blocks.3.0.out_layers.3.weight: 1327104\n","  [TRAINABLE] output_blocks.3.0.out_layers.3.bias: 384\n","  [TRAINABLE] output_blocks.3.0.skip_connection.weight: 245760\n","  [TRAINABLE] output_blocks.3.0.skip_connection.bias: 384\n","  [TRAINABLE] output_blocks.3.1.conv.weight: 1327104\n","  [TRAINABLE] output_blocks.3.1.conv.bias: 384\n","  [TRAINABLE] output_blocks.4.0.in_layers.0.weight: 640\n","  [TRAINABLE] output_blocks.4.0.in_layers.0.bias: 640\n","  [TRAINABLE] output_blocks.4.0.in_layers.2.weight: 1474560\n","  [TRAINABLE] output_blocks.4.0.in_layers.2.bias: 256\n","  [TRAINABLE] output_blocks.4.0.emb_layers.1.weight: 262144\n","  [TRAINABLE] output_blocks.4.0.emb_layers.1.bias: 512\n","  [TRAINABLE] output_blocks.4.0.out_layers.0.weight: 256\n","  [TRAINABLE] output_blocks.4.0.out_layers.0.bias: 256\n","  [TRAINABLE] output_blocks.4.0.out_layers.3.weight: 589824\n","  [TRAINABLE] output_blocks.4.0.out_layers.3.bias: 256\n","  [TRAINABLE] output_blocks.4.0.skip_connection.weight: 163840\n","  [TRAINABLE] output_blocks.4.0.skip_connection.bias: 256\n","  [TRAINABLE] output_blocks.5.0.in_layers.0.weight: 384\n","  [TRAINABLE] output_blocks.5.0.in_layers.0.bias: 384\n","  [TRAINABLE] output_blocks.5.0.in_layers.2.weight: 884736\n","  [TRAINABLE] output_blocks.5.0.in_layers.2.bias: 256\n","  [TRAINABLE] output_blocks.5.0.emb_layers.1.weight: 262144\n","  [TRAINABLE] output_blocks.5.0.emb_layers.1.bias: 512\n","  [TRAINABLE] output_blocks.5.0.out_layers.0.weight: 256\n","  [TRAINABLE] output_blocks.5.0.out_layers.0.bias: 256\n","  [TRAINABLE] output_blocks.5.0.out_layers.3.weight: 589824\n","  [TRAINABLE] output_blocks.5.0.out_layers.3.bias: 256\n","  [TRAINABLE] output_blocks.5.0.skip_connection.weight: 98304\n","  [TRAINABLE] output_blocks.5.0.skip_connection.bias: 256\n","  [TRAINABLE] output_blocks.5.1.conv.weight: 589824\n","  [TRAINABLE] output_blocks.5.1.conv.bias: 256\n","  [TRAINABLE] output_blocks.6.0.in_layers.0.weight: 384\n","  [TRAINABLE] output_blocks.6.0.in_layers.0.bias: 384\n","  [TRAINABLE] output_blocks.6.0.in_layers.2.weight: 442368\n","  [TRAINABLE] output_blocks.6.0.in_layers.2.bias: 128\n","  [TRAINABLE] output_blocks.6.0.emb_layers.1.weight: 131072\n","  [TRAINABLE] output_blocks.6.0.emb_layers.1.bias: 256\n","  [TRAINABLE] output_blocks.6.0.out_layers.0.weight: 128\n","  [TRAINABLE] output_blocks.6.0.out_layers.0.bias: 128\n","  [TRAINABLE] output_blocks.6.0.out_layers.3.weight: 147456\n","  [TRAINABLE] output_blocks.6.0.out_layers.3.bias: 128\n","  [TRAINABLE] output_blocks.6.0.skip_connection.weight: 49152\n","  [TRAINABLE] output_blocks.6.0.skip_connection.bias: 128\n","  [TRAINABLE] output_blocks.7.0.in_layers.0.weight: 256\n","  [TRAINABLE] output_blocks.7.0.in_layers.0.bias: 256\n","  [TRAINABLE] output_blocks.7.0.in_layers.2.weight: 294912\n","  [TRAINABLE] output_blocks.7.0.in_layers.2.bias: 128\n","  [TRAINABLE] output_blocks.7.0.emb_layers.1.weight: 131072\n","  [TRAINABLE] output_blocks.7.0.emb_layers.1.bias: 256\n","  [TRAINABLE] output_blocks.7.0.out_layers.0.weight: 128\n","  [TRAINABLE] output_blocks.7.0.out_layers.0.bias: 128\n","  [TRAINABLE] output_blocks.7.0.out_layers.3.weight: 147456\n","  [TRAINABLE] output_blocks.7.0.out_layers.3.bias: 128\n","  [TRAINABLE] output_blocks.7.0.skip_connection.weight: 32768\n","  [TRAINABLE] output_blocks.7.0.skip_connection.bias: 128\n","  [TRAINABLE] out.0.weight: 128\n","  [TRAINABLE] out.0.bias: 128\n","  [TRAINABLE] out.2.weight: 2304\n","  [TRAINABLE] out.2.bias: 2\n","  [TRAINABLE] hwm.conv_blocks_localization.0.0.blocks.0.conv.weight: 4147200\n","  [TRAINABLE] hwm.conv_blocks_localization.0.0.blocks.0.conv.bias: 480\n","  [TRAINABLE] hwm.conv_blocks_localization.0.0.blocks.0.instnorm.weight: 480\n","  [TRAINABLE] hwm.conv_blocks_localization.0.0.blocks.0.instnorm.bias: 480\n","  [TRAINABLE] hwm.conv_blocks_localization.0.1.blocks.0.conv.weight: 1105920\n","  [TRAINABLE] hwm.conv_blocks_localization.0.1.blocks.0.conv.bias: 256\n","  [TRAINABLE] hwm.conv_blocks_localization.0.1.blocks.0.instnorm.weight: 256\n","  [TRAINABLE] hwm.conv_blocks_localization.0.1.blocks.0.instnorm.bias: 256\n","  [TRAINABLE] hwm.conv_blocks_localization.1.0.blocks.0.conv.weight: 1179648\n","  [TRAINABLE] hwm.conv_blocks_localization.1.0.blocks.0.conv.bias: 256\n","  [TRAINABLE] hwm.conv_blocks_localization.1.0.blocks.0.instnorm.weight: 256\n","  [TRAINABLE] hwm.conv_blocks_localization.1.0.blocks.0.instnorm.bias: 256\n","  [TRAINABLE] hwm.conv_blocks_localization.1.1.blocks.0.conv.weight: 294912\n","  [TRAINABLE] hwm.conv_blocks_localization.1.1.blocks.0.conv.bias: 128\n","  [TRAINABLE] hwm.conv_blocks_localization.1.1.blocks.0.instnorm.weight: 128\n","  [TRAINABLE] hwm.conv_blocks_localization.1.1.blocks.0.instnorm.bias: 128\n","  [TRAINABLE] hwm.conv_blocks_localization.2.0.blocks.0.conv.weight: 294912\n","  [TRAINABLE] hwm.conv_blocks_localization.2.0.blocks.0.conv.bias: 128\n","  [TRAINABLE] hwm.conv_blocks_localization.2.0.blocks.0.instnorm.weight: 128\n","  [TRAINABLE] hwm.conv_blocks_localization.2.0.blocks.0.instnorm.bias: 128\n","  [TRAINABLE] hwm.conv_blocks_localization.2.1.blocks.0.conv.weight: 73728\n","  [TRAINABLE] hwm.conv_blocks_localization.2.1.blocks.0.conv.bias: 64\n","  [TRAINABLE] hwm.conv_blocks_localization.2.1.blocks.0.instnorm.weight: 64\n","  [TRAINABLE] hwm.conv_blocks_localization.2.1.blocks.0.instnorm.bias: 64\n","  [TRAINABLE] hwm.conv_blocks_localization.3.0.blocks.0.conv.weight: 73728\n","  [TRAINABLE] hwm.conv_blocks_localization.3.0.blocks.0.conv.bias: 64\n","  [TRAINABLE] hwm.conv_blocks_localization.3.0.blocks.0.instnorm.weight: 64\n","  [TRAINABLE] hwm.conv_blocks_localization.3.0.blocks.0.instnorm.bias: 64\n","  [TRAINABLE] hwm.conv_blocks_localization.3.1.blocks.0.conv.weight: 18432\n","  [TRAINABLE] hwm.conv_blocks_localization.3.1.blocks.0.conv.bias: 32\n","  [TRAINABLE] hwm.conv_blocks_localization.3.1.blocks.0.instnorm.weight: 32\n","  [TRAINABLE] hwm.conv_blocks_localization.3.1.blocks.0.instnorm.bias: 32\n","  [TRAINABLE] hwm.conv_blocks_localization.4.0.blocks.0.conv.weight: 18432\n","  [TRAINABLE] hwm.conv_blocks_localization.4.0.blocks.0.conv.bias: 32\n","  [TRAINABLE] hwm.conv_blocks_localization.4.0.blocks.0.instnorm.weight: 32\n","  [TRAINABLE] hwm.conv_blocks_localization.4.0.blocks.0.instnorm.bias: 32\n","  [TRAINABLE] hwm.conv_blocks_localization.4.1.blocks.0.conv.weight: 9216\n","  [TRAINABLE] hwm.conv_blocks_localization.4.1.blocks.0.conv.bias: 32\n","  [TRAINABLE] hwm.conv_blocks_localization.4.1.blocks.0.instnorm.weight: 32\n","  [TRAINABLE] hwm.conv_blocks_localization.4.1.blocks.0.instnorm.bias: 32\n","  [TRAINABLE] hwm.conv_blocks_context.0.blocks.0.conv.weight: 1152\n","  [TRAINABLE] hwm.conv_blocks_context.0.blocks.0.conv.bias: 32\n","  [TRAINABLE] hwm.conv_blocks_context.0.blocks.0.instnorm.weight: 32\n","  [TRAINABLE] hwm.conv_blocks_context.0.blocks.0.instnorm.bias: 32\n","  [TRAINABLE] hwm.conv_blocks_context.0.blocks.1.conv.weight: 9216\n","  [TRAINABLE] hwm.conv_blocks_context.0.blocks.1.conv.bias: 32\n","  [TRAINABLE] hwm.conv_blocks_context.0.blocks.1.instnorm.weight: 32\n","  [TRAINABLE] hwm.conv_blocks_context.0.blocks.1.instnorm.bias: 32\n","  [TRAINABLE] hwm.conv_blocks_context.1.blocks.0.conv.weight: 18432\n","  [TRAINABLE] hwm.conv_blocks_context.1.blocks.0.conv.bias: 64\n","  [TRAINABLE] hwm.conv_blocks_context.1.blocks.0.instnorm.weight: 64\n","  [TRAINABLE] hwm.conv_blocks_context.1.blocks.0.instnorm.bias: 64\n","  [TRAINABLE] hwm.conv_blocks_context.1.blocks.1.conv.weight: 36864\n","  [TRAINABLE] hwm.conv_blocks_context.1.blocks.1.conv.bias: 64\n","  [TRAINABLE] hwm.conv_blocks_context.1.blocks.1.instnorm.weight: 64\n","  [TRAINABLE] hwm.conv_blocks_context.1.blocks.1.instnorm.bias: 64\n","  [TRAINABLE] hwm.conv_blocks_context.2.blocks.0.conv.weight: 73728\n","  [TRAINABLE] hwm.conv_blocks_context.2.blocks.0.conv.bias: 128\n","  [TRAINABLE] hwm.conv_blocks_context.2.blocks.0.instnorm.weight: 128\n","  [TRAINABLE] hwm.conv_blocks_context.2.blocks.0.instnorm.bias: 128\n","  [TRAINABLE] hwm.conv_blocks_context.2.blocks.1.conv.weight: 147456\n","  [TRAINABLE] hwm.conv_blocks_context.2.blocks.1.conv.bias: 128\n","  [TRAINABLE] hwm.conv_blocks_context.2.blocks.1.instnorm.weight: 128\n","  [TRAINABLE] hwm.conv_blocks_context.2.blocks.1.instnorm.bias: 128\n","  [TRAINABLE] hwm.conv_blocks_context.3.blocks.0.conv.weight: 294912\n","  [TRAINABLE] hwm.conv_blocks_context.3.blocks.0.conv.bias: 256\n","  [TRAINABLE] hwm.conv_blocks_context.3.blocks.0.instnorm.weight: 256\n","  [TRAINABLE] hwm.conv_blocks_context.3.blocks.0.instnorm.bias: 256\n","  [TRAINABLE] hwm.conv_blocks_context.3.blocks.1.conv.weight: 589824\n","  [TRAINABLE] hwm.conv_blocks_context.3.blocks.1.conv.bias: 256\n","  [TRAINABLE] hwm.conv_blocks_context.3.blocks.1.instnorm.weight: 256\n","  [TRAINABLE] hwm.conv_blocks_context.3.blocks.1.instnorm.bias: 256\n","  [TRAINABLE] hwm.conv_blocks_context.4.blocks.0.conv.weight: 1105920\n","  [TRAINABLE] hwm.conv_blocks_context.4.blocks.0.conv.bias: 480\n","  [TRAINABLE] hwm.conv_blocks_context.4.blocks.0.instnorm.weight: 480\n","  [TRAINABLE] hwm.conv_blocks_context.4.blocks.0.instnorm.bias: 480\n","  [TRAINABLE] hwm.conv_blocks_context.4.blocks.1.conv.weight: 2073600\n","  [TRAINABLE] hwm.conv_blocks_context.4.blocks.1.conv.bias: 480\n","  [TRAINABLE] hwm.conv_blocks_context.4.blocks.1.instnorm.weight: 480\n","  [TRAINABLE] hwm.conv_blocks_context.4.blocks.1.instnorm.bias: 480\n","  [TRAINABLE] hwm.conv_blocks_context.5.0.blocks.0.conv.weight: 2073600\n","  [TRAINABLE] hwm.conv_blocks_context.5.0.blocks.0.conv.bias: 480\n","  [TRAINABLE] hwm.conv_blocks_context.5.0.blocks.0.instnorm.weight: 480\n","  [TRAINABLE] hwm.conv_blocks_context.5.0.blocks.0.instnorm.bias: 480\n","  [TRAINABLE] hwm.conv_blocks_context.5.1.blocks.0.conv.weight: 2073600\n","  [TRAINABLE] hwm.conv_blocks_context.5.1.blocks.0.conv.bias: 480\n","  [TRAINABLE] hwm.conv_blocks_context.5.1.blocks.0.instnorm.weight: 480\n","  [TRAINABLE] hwm.conv_blocks_context.5.1.blocks.0.instnorm.bias: 480\n","  [TRAINABLE] hwm.seg_outputs.0.weight: 32\n","\n","总参数: 77,075,108\n","可训练参数: 76,943,266\n","冻结参数: 131,842\n","可训练比例: 99.83%\n","\n","training...\n","---------------------------\n","| grad_norm    | 1        |\n","| loss         | 1        |\n","| loss_cal     | 0.181    |\n","| loss_cal_q0  | 0.16     |\n","| loss_cal_q2  | 0.188    |\n","| loss_cal_q3  | 0.181    |\n","| loss_diff    | 1        |\n","| loss_diff_q0 | 1.01     |\n","| loss_diff_q2 | 0.997    |\n","| loss_diff_q3 | 1        |\n","| loss_q0      | 1.01     |\n","| loss_q2      | 0.997    |\n","| loss_q3      | 1        |\n","| loss_seg     | 2.81     |\n","| loss_total   | 2.81     |\n","| param_norm   | 191      |\n","| samples      | 8        |\n","| seg_dice     | 1e-08    |\n","| seg_iou      | 1e-08    |\n","| step         | 0        |\n","---------------------------\n","saving model 0...\n","saving model 0.9999...\n","/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n","  warnings.warn(  # warn only once\n","[rank0]: Traceback (most recent call last):\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-2/scripts/segmentation_train3stages.py\", line 329, in <module>\n","[rank0]:     main()\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-2/scripts/segmentation_train3stages.py\", line 289, in main\n","[rank0]:     ).run_loop()\n","[rank0]:       ^^^^^^^^^^\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-2/guided_diffusion/train_util.py\", line 225, in run_loop\n","[rank0]:     batch, cond, name = next(data_iter)\n","[rank0]:                         ^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 734, in __next__\n","[rank0]:     data = self._next_data()\n","[rank0]:            ^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 790, in _next_data\n","[rank0]:     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n","[rank0]:     data = [self.dataset[idx] for idx in possibly_batched_index]\n","[rank0]:             ~~~~~~~~~~~~^^^^^\n","[rank0]:   File \"/content/drive/MyDrive/Colab Notebooks/6204-2/guided_diffusion/bratsloader.py\", line 344, in __getitem__\n","[rank0]:     o = torch.tensor(nib_img.get_fdata())[:,:,slice_idx]\n","[rank0]:                      ^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/nibabel/dataobj_images.py\", line 374, in get_fdata\n","[rank0]:     data = np.asanyarray(self._dataobj, dtype=dtype)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/nibabel/arrayproxy.py\", line 454, in __array__\n","[rank0]:     arr = self._get_scaled(dtype=dtype, slicer=())\n","[rank0]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/nibabel/arrayproxy.py\", line 423, in _get_scaled\n","[rank0]:     scaled = scaled.astype(np.promote_types(scaled.dtype, dtype), copy=False)\n","[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]: KeyboardInterrupt\n","[rank0]:[W1022 14:25:09.953785698 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"]}]}]}